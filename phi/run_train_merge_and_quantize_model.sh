#!/bin/bash
set -e

MODEL_PATH="./out/Phi-3-mini-128k-instruct_merged_r128_sensitive/merged_model"
GGUF_DIR="/workspace/gguf_models"

echo "í•™ìŠµ, ë³‘í•© ë° GGUF ë³€í™˜ í”„ë¡œì„¸ìŠ¤ ì‹œì‘"
echo "ì‹¤ì œ ëª¨ë¸ ê²½ë¡œ: $MODEL_PATH"

# ìˆ˜ì •ëœ ì²´í¬ í•¨ìˆ˜ - ë¶„í• ëœ safetensors íŒŒì¼ ì§€ì›
check_training_completed() {
    if [ -d "$MODEL_PATH" ] && [ -f "$MODEL_PATH/config.json" ] && [ -f "$MODEL_PATH/tokenizer.json" ]; then
        # ë¶„í• ëœ safetensors íŒŒì¼ë„ ì²´í¬
        if [ -f "$MODEL_PATH/pytorch_model.bin" ] || [ -f "$MODEL_PATH/model.safetensors" ] || [ -f "$MODEL_PATH/model-00001-of-00002.safetensors" ]; then
            return 0  # í•™ìŠµ ì™„ë£Œ
        fi
    fi
    return 1  # í•™ìŠµ ë¯¸ì™„ë£Œ
}

if check_training_completed; then
    echo "âœ… í•™ìŠµì´ ì´ë¯¸ ì™„ë£Œë˜ì–´ ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤!"
else
    echo "ğŸš€ LoRA í•™ìŠµ ë° ë³‘í•© ì‹œì‘..."
    python train_and_merge_lora.py
fi

echo "ğŸ”„ GGUF ë³€í™˜ ë° ì–‘ìí™” ì‹œì‘..."
bash convert_merged_model_to_gguf.sh

echo "ğŸ‰ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!"
