#!/bin/bash
# λ² μ΄μ¤ λ¨λΈ μ–‘μν™” μ „μ© μ›ν¬ν”λ΅μ°: μμ΅΄μ„± μ„¤μΉ -> λ² μ΄μ¤ λ¨λΈ λ‹¤μ΄λ΅λ“ λ° GGUF λ³€ν™

set -e

echo "π€ λ² μ΄μ¤ λ¨λΈ μ–‘μν™” μ›ν¬ν”λ΅μ°λ¥Ό μ‹μ‘ν•©λ‹λ‹¤."
echo "=================================================="

# --- 1λ‹¨κ³„: ν•„μ μμ΅΄μ„± μ„¤μΉ ---
echo "β… 1. ν•„μ μμ΅΄μ„±μ„ μ„¤μΉν•©λ‹λ‹¤..."

# Python ν¨ν‚¤μ§€ μ„¤μΉ
pip install torch transformers datasets huggingface-hub

# μ‹μ¤ν… ν¨ν‚¤μ§€ μ„¤μΉ (μ΄λ―Έ μ„¤μΉλμ–΄ μμ„ κ°€λ¥μ„±μ΄ λ†’μ§€λ§ ν™•μΈ)
if command -v apt-get &> /dev/null; then
    echo "π“¦ μ‹μ¤ν… ν¨ν‚¤μ§€ ν™•μΈ μ¤‘..."
    apt-get update -qq
    apt-get install -y cmake build-essential libcurl4-openssl-dev
elif command -v yum &> /dev/null; then
    echo "π“¦ yum ν¨ν‚¤μ§€ λ§¤λ‹μ € κ°μ§€. cmakeμ™€ libcurl-devel μ„¤μΉ μ¤‘..."
    yum install -y cmake libcurl-devel
elif command -v dnf &> /dev/null; then
    echo "π“¦ dnf ν¨ν‚¤μ§€ λ§¤λ‹μ € κ°μ§€. cmakeμ™€ libcurl-devel μ„¤μΉ μ¤‘..."
    dnf install -y cmake libcurl-devel
else
    echo "β οΈ μ§€μ›λλ” ν¨ν‚¤μ§€ λ§¤λ‹μ €λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
    echo "cmakeμ™€ libcurlμ΄ μ΄λ―Έ μ„¤μΉλμ–΄ μλ‹¤κ³  κ°€μ •ν•©λ‹λ‹¤."
fi

echo "β… μμ΅΄μ„± μ„¤μΉ μ™„λ£"
echo "--------------------------------------------------"

# --- 2λ‹¨κ³„: λ² μ΄μ¤ λ¨λΈ μ„ νƒ ---
echo "β… 2. λ² μ΄μ¤ λ¨λΈμ„ μ„ νƒν•©λ‹λ‹¤..."

# μ‚¬μ©μκ°€ λ§¤κ°λ³€μλ΅ λ¨λΈμ„ μ§€μ •ν–λ”μ§€ ν™•μΈ
if [ -z "$1" ]; then
    echo "μ‚¬μ© κ°€λ¥ν• λ² μ΄μ¤ λ¨λΈλ“¤:"
    echo "  1. microsoft/Phi-3-mini-128k-instruct (κΈ°λ³Έκ°’)"
    echo "  2. microsoft/Phi-3.5-mini-instruct"
    echo "  3. microsoft/Phi-3-medium-128k-instruct"
    echo "  4. meta-llama/Meta-Llama-3.1-8B-Instruct"
    echo ""
    echo "κΈ°λ³Έ λ¨λΈ(Phi-3-mini-128k-instruct)μ„ μ‚¬μ©ν•©λ‹λ‹¤."
    MODEL_ID="microsoft/Phi-3-mini-128k-instruct"
else
    MODEL_ID="$1"
    echo "μ§€μ •λ λ¨λΈ: $MODEL_ID"
fi

echo "π“ μ„ νƒλ λ¨λΈ: $MODEL_ID"
echo "--------------------------------------------------"

# --- 3λ‹¨κ³„: λ² μ΄μ¤ λ¨λΈ λ³€ν™ μ¤ν¬λ¦½νΈ ν™•μΈ ---
echo "β… 3. λ² μ΄μ¤ λ¨λΈ λ³€ν™ μ¤ν¬λ¦½νΈλ¥Ό μ¤€λΉ„ν•©λ‹λ‹¤..."

if [ ! -f "convert_base_model_to_gguf.sh" ]; then
    echo "β λ² μ΄μ¤ λ¨λΈ λ³€ν™ μ¤ν¬λ¦½νΈ 'convert_base_model_to_gguf.sh'λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
    echo "ν„μ¬ λ””λ ‰ν† λ¦¬μ μ¤ν¬λ¦½νΈ νμΌλ“¤:"
    ls -la *.sh 2>/dev/null || echo "μ‰ μ¤ν¬λ¦½νΈ νμΌμ΄ μ—†μµλ‹λ‹¤."
    exit 1
fi

chmod +x convert_base_model_to_gguf.sh
echo "β… λ² μ΄μ¤ λ¨λΈ λ³€ν™ μ¤ν¬λ¦½νΈ μ¤€λΉ„ μ™„λ£"
echo "--------------------------------------------------"

# --- 4λ‹¨κ³„: λ² μ΄μ¤ λ¨λΈ GGUF λ³€ν™ λ° μ–‘μν™” ---
echo "β… 4. λ² μ΄μ¤ λ¨λΈ GGUF λ³€ν™ λ° μ–‘μν™”λ¥Ό μ‹μ‘ν•©λ‹λ‹¤..."
echo "   λ¨λΈ: $MODEL_ID"
echo "   μμƒ μ†μ” μ‹κ°„: 10-30λ¶„ (λ¨λΈ ν¬κΈ° λ° μ‹μ¤ν… μ„±λ¥μ— λ”°λΌ)"
echo ""

./convert_base_model_to_gguf.sh "$MODEL_ID"

echo "--------------------------------------------------"

# --- 5λ‹¨κ³„: κ²°κ³Ό ν™•μΈ λ° μ •λ¦¬ ---
echo "β… 5. μƒμ„±λ GGUF νμΌλ“¤μ„ ν™•μΈν•©λ‹λ‹¤..."

if [ -d "/workspace/gguf_models" ]; then
    echo ""
    echo "π“ μƒμ„±λ λ² μ΄μ¤ λ¨λΈ GGUF νμΌλ“¤:"
    ls -lh /workspace/gguf_models/*-base-*.gguf | awk '{print "   π“„ " $9 " (" $5 ")"}'

    # μ΄ ν¬κΈ° κ³„μ‚°
    TOTAL_SIZE=$(du -sh /workspace/gguf_models/ | cut -f1)
    echo ""
    echo "π“ gguf_models λ””λ ‰ν† λ¦¬ μ΄ ν¬κΈ°: $TOTAL_SIZE"

    # μ¶”μ² λ¨λΈ ν‘μ‹
    echo ""
    echo "π’΅ λ² μ΄μ¤ λ¨λΈ μ¶”μ² μ‚¬μ©λ²•:"
    if ls /workspace/gguf_models/*-base-q4_k_m.gguf 1> /dev/null 2>&1; then
        Q4_FILE=$(ls /workspace/gguf_models/*-base-q4_k_m.gguf | head -1)
        Q4_SIZE=$(du -h "$Q4_FILE" | cut -f1)
        echo "   π― κ· ν•μ΅ν μ„±λ¥: $(basename "$Q4_FILE") ($Q4_SIZE)"
    fi

    if ls /workspace/gguf_models/*-base-q4_0.gguf 1> /dev/null 2>&1; then
        Q4_0_FILE=$(ls /workspace/gguf_models/*-base-q4_0.gguf | head -1)
        Q4_0_SIZE=$(du -h "$Q4_0_FILE" | cut -f1)
        echo "   β΅ λΉ λ¥Έ μ¶”λ΅ : $(basename "$Q4_0_FILE") ($Q4_0_SIZE)"
    fi

    if ls /workspace/gguf_models/*-base-q5_k_m.gguf 1> /dev/null 2>&1; then
        Q5_FILE=$(ls /workspace/gguf_models/*-base-q5_k_m.gguf | head -1)
        Q5_SIZE=$(du -h "$Q5_FILE" | cut -f1)
        echo "   π† κ³ ν’μ§: $(basename "$Q5_FILE") ($Q5_SIZE)"
    fi

else
    echo "β GGUF λ¨λΈ λ””λ ‰ν† λ¦¬λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
    echo "λ³€ν™ κ³Όμ •μ—μ„ λ¬Έμ κ°€ λ°μƒν–μ„ μ μμµλ‹λ‹¤."
    exit 1
fi

echo ""
echo "π‰ λ² μ΄μ¤ λ¨λΈ μ–‘μν™”κ°€ μ„±κ³µμ μΌλ΅ μ™„λ£λμ—μµλ‹λ‹¤!"
echo "=================================================="
echo "π“ μ™„λ£λ μ‘μ—…:"
echo "   β… $MODEL_ID λ‹¤μ΄λ΅λ“"
echo "   β… ν† ν¬λ‚μ΄μ € λ¬Έμ  ν•΄κ²°"
echo "   β… FP16 GGUF λ³€ν™"
echo "   β… 5κ°€μ§€ μ–‘μν™” λ λ²¨ μƒμ„± (Q4_0, Q4_K_M, Q5_K_M, Q6_K, Q8_0)"
echo ""
echo "π” νμΈνλ‹ λ¨λΈκ³Ό λΉ„κµ:"
echo "   λ² μ΄μ¤ λ¨λΈ: *-base-*.gguf"
echo "   νμΈνλ‹ λ¨λΈ: merged_model-finetuned-*.gguf"
echo ""
echo "π–¥οΈ μ‚¬μ© λ°©λ²•:"
echo "   1. μƒμ„±λ .gguf νμΌμ„ λ΅μ»¬ λ¨Έμ‹ μΌλ΅ λ‹¤μ΄λ΅λ“"
echo "   2. llama.cpp λλ” Ollama λ“±μ λ„κµ¬λ΅ μ‹¤ν–‰"
echo "   3. μμ‹: ./llama-cli -m model.gguf -p \"Your prompt here\""
echo ""
echo "π“ μ„±λ¥ λΉ„κµ ν:"
echo "   λ™μΌν• ν”„λ΅¬ν”„νΈλ΅ λ² μ΄μ¤ λ¨λΈκ³Ό νμΈνλ‹ λ¨λΈμ„ ν…μ¤νΈν•μ—¬"
echo "   νμΈνλ‹ ν¨κ³Όλ¥Ό ν™•μΈν•΄λ³΄μ„Έμ”."
echo "=================================================="

# ==================================================
# ## β™οΈ Jupyter Notebook μ‹¤ν–‰ κ°€μ΄λ“
# ==================================================
#
# 1. μ‚¬μ „ μ¤€λΉ„:
#    - run_base_model_quantization.sh (π‘ μ΄ νμΌ)
#    - convert_base_model_to_gguf.sh (λ² μ΄μ¤ λ¨λΈ λ³€ν™ μ¤ν¬λ¦½νΈ)
#
# 2. μ‹¤ν–‰ λ°©λ²• (Jupyter Notebook μ…€):
#    # μ‹¤ν–‰ κ¶ν• λ¶€μ—¬
#    !chmod +x run_base_model_quantization.sh
#    !chmod +x convert_base_model_to_gguf.sh
#
#    # κΈ°λ³Έ λ¨λΈ μ–‘μν™”
#    !./run_base_model_quantization.sh
#
#    # λ‹¤λ¥Έ λ¨λΈ μ–‘μν™” μμ‹
#    !./run_base_model_quantization.sh "microsoft/Phi-3.5-mini-instruct"