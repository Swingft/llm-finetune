#!/bin/bash
# LoRA μ–΄λ‘ν„° ν•™μµ λ° GGUF λ³€ν™ μ›ν¬ν”λ΅μ° (v5.0: μμ΅΄μ„± μ¶©λ ν•΄κ²°)

set -e

echo "π€ LoRA μ–΄λ‘ν„° ν•™μµ λ° GGUF λ³€ν™ μ›ν¬ν”λ΅μ°λ¥Ό μ‹μ‘ν•©λ‹λ‹¤. (v5.0)"
echo "=================================================="

# --- 1λ‹¨κ³„: Python μμ΅΄μ„± μ„¤μΉ ---
echo "β… 1. Python μμ΅΄μ„±μ„ μ•μ •μ μΈ λ°©μ‹μΌλ΅ μ„¤μΉν•©λ‹λ‹¤..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers datasets peft trl bitsandbytes accelerate einops tiktoken huggingface-hub
echo "β… μμ΅΄μ„± μ„¤μΉ μ™„λ£."
echo "--------------------------------------------------"

# --- 2λ‹¨κ³„: ν•„μ νμΌ ν™•μΈ ---
echo "β… 2. ν•„μ νμΌλ“¤μ„ ν™•μΈν•©λ‹λ‹¤..."
if [ ! -f "json_data.jsonl" ]; then
    echo "β ν•™μµ λ°μ΄ν„° νμΌ 'json_data.jsonl'μ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
    exit 1
fi
if [ ! -f "train_lora_adapter.py" ]; then
    echo "β LoRA ν•™μµ μ¤ν¬λ¦½νΈ 'train_lora_adapter.py'λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
    exit 1
fi
if [ ! -f "convert_lora_to_gguf.sh" ]; then
    echo "β GGUF λ³€ν™ μ¤ν¬λ¦½νΈ 'convert_lora_to_gguf.sh'λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
    exit 1
fi
echo "β… λ¨λ“  ν•„μ νμΌ ν™•μΈ μ™„λ£."
echo "--------------------------------------------------"

# --- 3λ‹¨κ³„: κΈ°μ΅΄ ν•™μµ κ²°κ³Ό ν™•μΈ λ° νμΈνλ‹ ---
echo "β… 3. κΈ°μ΅΄ ν•™μµ κ²°κ³Όλ¥Ό ν™•μΈν•©λ‹λ‹¤..."
mkdir -p ./out
LATEST_ADAPTER_DIR=$(find ./out -mindepth 1 -maxdepth 1 -type d -printf '%T@ %p\n' 2>/dev/null | sort -nr | head -1 | cut -d' ' -f2-)

if [ -n "$LATEST_ADAPTER_DIR" ] && [ -f "$LATEST_ADAPTER_DIR/adapter_config.json" ]; then
    echo "β… μ΄λ―Έ ν•™μµλ μ ν¨ν• μ–΄λ‘ν„°λ¥Ό μ°Ύμ•μµλ‹λ‹¤."
    echo "   κ²½λ΅: $LATEST_ADAPTER_DIR"
    echo "   >> νμΈνλ‹ λ‹¨κ³„λ¥Ό κ±΄λ„λλ‹λ‹¤."
    echo "--------------------------------------------------"
else
    echo "β„ΉοΈ  κΈ°μ΅΄ ν•™μµ κ²°κ³Όλ¥Ό μ°Ύμ„ μ μ—†κ±°λ‚ μ ν¨ν•μ§€ μ•μµλ‹λ‹¤. μƒλ΅ νμΈνλ‹μ„ μ‹μ‘ν•©λ‹λ‹¤."
    echo "--------------------------------------------------"
    echo "π€ 3-1. LoRA μ–΄λ‘ν„° νμΈνλ‹μ„ μ‹μ‘ν•©λ‹λ‹¤..."
    echo "   μμƒ μ†μ” μ‹κ°„: 20-40λ¶„ (λ°μ΄ν„° ν¬κΈ° λ° ν•λ“μ›¨μ–΄μ— λ”°λΌ)"
    python train_lora_adapter.py
    echo "--------------------------------------------------"
    LATEST_ADAPTER_DIR=$(find ./out -mindepth 1 -maxdepth 1 -type d -printf '%T@ %p\n' 2>/dev/null | sort -nr | head -1 | cut -d' ' -f2-)
    if [ ! -f "$LATEST_ADAPTER_DIR/adapter_config.json" ]; then
        echo "β ν•™μµ ν›„ μ ν¨ν• μ–΄λ‘ν„°λ¥Ό μ°Ύμ§€ λ»ν–μµλ‹λ‹¤."
        exit 1
    fi
fi

echo "β… μµμΆ… μ–΄λ‘ν„° ν™•μΈ μ™„λ£: $LATEST_ADAPTER_DIR"
ADAPTER_SIZE=$(du -sh "$LATEST_ADAPTER_DIR" | cut -f1)
echo "π“ μ–΄λ‘ν„° ν¬κΈ°: $ADAPTER_SIZE"
echo "--------------------------------------------------"

# --- 4λ‹¨κ³„: GGUF λ³€ν™ μ¤ν¬λ¦½νΈ μμ • ---
echo "β… 4. μμ΅΄μ„± μ¶©λ λ°©μ§€λ¥Ό μ„ν•΄ GGUF λ³€ν™ μ¤ν¬λ¦½νΈλ¥Ό μμ •ν•©λ‹λ‹¤..."
# convert_lora_to_gguf.sh λ‚΄λ¶€μ 'pip install' λ…λ Ήμ–΄λ¥Ό μ£Όμ„ μ²λ¦¬ν•μ—¬,
# μ΄λ―Έ μ„¤μΉλ μ•μ •μ μΈ λΌμ΄λΈλ¬λ¦¬ λ²„μ „μ΄ λ³€κ²½λμ§€ μ•λ„λ΅ ν•©λ‹λ‹¤.
sed -i "s/pip install -q -r requirements.txt/# pip install -q -r requirements.txt/" "convert_lora_to_gguf.sh"
echo "β… GGUF λ³€ν™ μ¤ν¬λ¦½νΈ μμ • μ™„λ£."
echo "--------------------------------------------------"


# --- 5λ‹¨κ³„: LoRA μ–΄λ‘ν„° GGUF μ–‘μν™” ---
echo "β… 5. LoRA μ–΄λ‘ν„°λ¥Ό GGUFλ΅ λ³€ν™ν•©λ‹λ‹¤..."
echo ""
# GGUF λ³€ν™ μ¤ν¬λ¦½νΈ μ‹¤ν–‰
chmod +x convert_lora_to_gguf.sh
./convert_lora_to_gguf.sh "${LATEST_ADAPTER_DIR}"
echo "--------------------------------------------------"


echo ""
echo "π‰ μ „μ²΄ μ›ν¬ν”λ΅μ°κ°€ μ„±κ³µμ μΌλ΅ μ™„λ£λμ—μµλ‹λ‹¤!"
echo "=================================================="
echo "π“ μµμΆ… LoRA μ–΄λ‘ν„° κ²½λ΅: ${LATEST_ADAPTER_DIR}"
echo "   (GGUF νμΌμ€ /workspace/gguf_models/ λ””λ ‰ν† λ¦¬μ—μ„ ν™•μΈν•μ„Έμ”)"
echo ""
echo "π“ μ°Έκ³ μ‚¬ν•­:"
echo "   - μƒμ„±λ GGUF μ–΄λ‘ν„°λ” λ² μ΄μ¤ λ¨λΈκ³Ό ν•¨κ» μ‚¬μ©ν•΄μ•Ό ν•©λ‹λ‹¤."
echo "   - λ² μ΄μ¤ λ¨λΈ: microsoft/Phi-3-mini-128k-instruct"
echo "   - μ‚¬μ©λ²• μμ‹: ./llama-cli -m base.gguf --lora adapter.gguf -p \"prompt\""
echo "=================================================="

